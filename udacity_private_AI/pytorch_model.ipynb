{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#imports \n",
    "import torch as th\n",
    "import numpy as np \n",
    "from torch import nn,optim\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "#making the dummy data \n",
    "inp = th.tensor([[0,1],[1,2],[2,3],[3,4],[4,5],[5,6],[6,7],[7,8],[8,9],[9.,10]], requires_grad= True)\n",
    "target = th.tensor([[1],[2],[3],[4.],[5],[6],[7],[8],[9],[0]] , requires_grad= True)\n",
    "\n",
    "#other dummy data\n",
    "inp_2 = th.tensor([[0,0],[0,1],[1,0],[1,1.]], requires_grad= True)\n",
    "target_2 = th.tensor([[0],[0],[1],[1.]] , requires_grad= True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Network(\n",
       "  (fc1): Linear(in_features=2, out_features=10, bias=True)\n",
       "  (fc2): Linear(in_features=10, out_features=1, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "#the toy model \n",
    "class Network(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Network,self).__init__()\n",
    "        self.fc1 = nn.Linear(2,10)\n",
    "        self.fc2 = nn.Linear(10,1)\n",
    "    def forward(self,x):\n",
    "        x = self.fc1(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "\n",
    "network = Network()\n",
    "network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(16.8271, grad_fn=<SumBackward0>)\n",
      "tensor(7.9613, grad_fn=<SumBackward0>)\n",
      "tensor(1.1399, grad_fn=<SumBackward0>)\n",
      "tensor(0.9090, grad_fn=<SumBackward0>)\n",
      "tensor(0.8528, grad_fn=<SumBackward0>)\n",
      "tensor(0.8059, grad_fn=<SumBackward0>)\n",
      "tensor(0.7629, grad_fn=<SumBackward0>)\n",
      "tensor(0.7233, grad_fn=<SumBackward0>)\n",
      "tensor(0.6868, grad_fn=<SumBackward0>)\n",
      "tensor(0.6536, grad_fn=<SumBackward0>)\n",
      "tensor(0.6238, grad_fn=<SumBackward0>)\n",
      "tensor(0.6069, grad_fn=<SumBackward0>)\n",
      "tensor(0.5767, grad_fn=<SumBackward0>)\n",
      "tensor(0.4180, grad_fn=<SumBackward0>)\n",
      "tensor(0.3380, grad_fn=<SumBackward0>)\n",
      "tensor(0.2443, grad_fn=<SumBackward0>)\n",
      "tensor(0.1805, grad_fn=<SumBackward0>)\n",
      "tensor(0.1133, grad_fn=<SumBackward0>)\n",
      "tensor(0.0896, grad_fn=<SumBackward0>)\n",
      "tensor(0.0605, grad_fn=<SumBackward0>)\n"
     ]
    }
   ],
   "source": [
    "#training method \n",
    "def train():\n",
    "    #training logic \n",
    "    #train optimizer \n",
    "    opt = optim.SGD(params=network.parameters(), lr=0.1) \n",
    "    for i in range(20):\n",
    "        #making the gradient zero\n",
    "        opt.zero_grad()\n",
    "\n",
    "        #make a prediction\n",
    "        pred = network(inp_2)  #passing the data\n",
    "\n",
    "        #calculation of the loss \n",
    "        loss = ((pred - target_2)**2).sum()\n",
    "\n",
    "        #backward steps for backprop\n",
    "        loss.backward()\n",
    "\n",
    "        #stepping for optmizer \n",
    "        opt.step()\n",
    "\n",
    "        #print the loss\n",
    "        print(loss)\n",
    "\n",
    "train()   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.0364],\n",
       "        [ 0.1046],\n",
       "        [ 0.8309],\n",
       "        [ 1.0566]], grad_fn=<AddmmBackward>)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "network(inp_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating a hook \n",
    "import syft as sy\n",
    "hook =sy.TorchHook(th)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Worker me already exists. Replacing old worker which could cause                     unexpected behavior\n",
      "Worker me already exists. Replacing old worker which could cause                     unexpected behavior\n",
      "Worker me already exists. Replacing old worker which could cause                     unexpected behavior\n"
     ]
    }
   ],
   "source": [
    "#creation of the workers \n",
    "bob = sy.VirtualWorker(hook, id = \"bob\").add_worker(sy.local_worker)\n",
    "alice = sy.VirtualWorker(hook, id= \"alice\").add_worker(sy.local_worker)\n",
    "secure_worker = sy.VirtualWorker(hook, id=\"secure_worker\").add_worker(sy.local_worker)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "#encypting the model\n",
    "encypted_model = network.fix_precision().share(alice, bob,crypto_provider= secure_worker)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Parameter containing:\n",
       " (Wrapper)>FixedPrecisionTensor>[AdditiveSharingTensor]\n",
       " \t-> [PointerTensor | me:36328489793 -> alice:6066174768]\n",
       " \t-> [PointerTensor | me:49276056213 -> bob:51813811006]\n",
       " \t*crypto provider: secure_worker*,\n",
       " Parameter containing:\n",
       " (Wrapper)>FixedPrecisionTensor>[AdditiveSharingTensor]\n",
       " \t-> [PointerTensor | me:35339522479 -> alice:27378373565]\n",
       " \t-> [PointerTensor | me:32207285278 -> bob:55909070512]\n",
       " \t*crypto provider: secure_worker*,\n",
       " Parameter containing:\n",
       " (Wrapper)>FixedPrecisionTensor>[AdditiveSharingTensor]\n",
       " \t-> [PointerTensor | me:46362332671 -> alice:11446719628]\n",
       " \t-> [PointerTensor | me:73725396889 -> bob:88485665780]\n",
       " \t*crypto provider: secure_worker*,\n",
       " Parameter containing:\n",
       " (Wrapper)>FixedPrecisionTensor>[AdditiveSharingTensor]\n",
       " \t-> [PointerTensor | me:9978673984 -> alice:1651963050]\n",
       " \t-> [PointerTensor | me:74567219640 -> bob:50629375631]\n",
       " \t*crypto provider: secure_worker*]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#checking for the encypted model in the system \n",
    "list(encypted_model.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "#encypting the data for input\n",
    "encypted_data = inp_2.fix_precision().share(alice,bob, crypto_provider = secure_worker)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ecncypting the data for the prediction\n",
    "encypted_pred = inp_2.fix_precision().share(alice, bob, crypto_provider = secure_worker)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/abhi/anaconda3/lib/python3.8/site-packages/syft/frameworks/torch/tensors/interpreters/additive_shared.py:122: UserWarning: Use dtype instead of field\n",
      "  warnings.warn(\"Use dtype instead of field\")\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(Wrapper)>FixedPrecisionTensor>[AdditiveSharingTensor]\n",
       "\t-> [PointerTensor | me:23002103296 -> alice:34093406614]\n",
       "\t-> [PointerTensor | me:70269851014 -> bob:6467384377]\n",
       "\t*crypto provider: secure_worker*"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#prediction of the model\n",
    "encypted_predition = encypted_model(encypted_data)\n",
    "encypted_predition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.0350],\n",
       "        [ 0.1050],\n",
       "        [ 0.8310],\n",
       "        [ 1.0550]])"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encypted_predition.get().float_precision()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "a9277649a74e8faa8be12cbeb58385da5eb2caa0505776957b10bd3c68ac62ba"
  },
  "kernelspec": {
   "display_name": "Python 3.8.5 64-bit ('base': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
