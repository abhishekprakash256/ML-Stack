The scrambing ideas for the the machine learning addition to the website as the hosting machine will be very expensive for the full machine 
-- use two instance , one for hsoting the instance , one for the GPU support in aws -- G4, G5, P4 instance 
-- these machine have GPU with choosing the ubuntu cuda installed images 




-- I can use SSH to work on the machine 
-- the other machine can talk to the GPU machine GRPC web client for bidiretional communication 
-- aws lambda can be used for machine sleeping and waking up calls 


-- For the code as insfrastructure I can use combination of terraform and ansible to deploy the code and run the production machine 
-- grpc protocals can be use to fetch the data from one machine to other machine 



for the LLM and ML tasks 

-- the hugging face models can be a starting point to deep dive 
-- LLM caching for faster responses 
-- 